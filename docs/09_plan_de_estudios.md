# Plan de Estudios â€” Ingeniero en Minas + Data Scientist
## Proyecto: TWS_ESPESADOR â€” Sistema Predictivo de Turbiedad

> **Para quiÃ©n es este documento**: Ingeniero en minas con experiencia en metalurgia, con conocimientos bÃ¡sicos de Python, construyendo un portafolio profesional de Data Science aplicado a procesos mineros.
>
> **FilosofÃ­a**: Aprender *justo a tiempo*. Cada concepto aparece cuando el proyecto lo necesita. La IA es tu tutor, no tu teclado.
>
> **Regla de oro**: Si llevas menos de 15 minutos atascado, sigue intentando. DespuÃ©s de 15 minutos, pide ayuda para *entender*, no para que te escriban el cÃ³digo.

---

## Mapa de Etapas

```
Etapa 0: Fundamentos Python para Datos          [COMPLETADA]
    â”‚
    â–¼
Etapa 1: EDA y DiagnÃ³stico Inicial              â† AquÃ­ empiezas
    â”‚
    â–¼
Etapa 2: Salud de Sensores (Sensor Health)
    â”‚
    â–¼
Etapa 3: VisualizaciÃ³n Operacional (Power BI)
    â”‚
    â–¼
Etapa 4: Feature Engineering Minero
    â”‚
    â–¼
Etapa 5: Modelado Predictivo Base
    â”‚
    â–¼
Etapa 6: Interpretabilidad y AnÃ¡lisis de Errores
    â”‚
    â–¼
Etapa 7: Despliegue y Portafolio Final
    â”‚
    â–¼
[Entregable]: Repositorio GitHub publicable +
              Informe estilo memoria de tÃ­tulo
```

---

## Estado del Proyecto al Inicio

```
âœ… HECHO
  â”œâ”€â”€ Dataset sintÃ©tico generado (90 dÃ­as, 5 min)
  â”œâ”€â”€ simulate_fixed.py funcionando y calibrado
  â”œâ”€â”€ EDA inicial (notebook 01_eda.ipynb)
  â”œâ”€â”€ Feature engineering preliminar
  â””â”€â”€ Estructura de carpetas src/ data/ docs/ notebooks/

ğŸ”² PENDIENTE
  â”œâ”€â”€ Sensor health module (detecciÃ³n de fallas)
  â”œâ”€â”€ Dashboard Power BI
  â”œâ”€â”€ Modelos ML entrenados y evaluados
  â”œâ”€â”€ Interpretabilidad (SHAP)
  â”œâ”€â”€ API de predicciÃ³n (opcional)
  â””â”€â”€ DocumentaciÃ³n final tipo memoria
```

---

## ETAPA 1 â€” ExploraciÃ³n Profunda y DiagnÃ³stico de Datos

> **AnalogÃ­a minera**: Antes de diseÃ±ar un circuito de flotaciÃ³n, el metalurgista hace pruebas de laboratorio para entender el mineral. El EDA es exactamente eso: entender tu "mineral" (los datos) antes de procesar.

### Objetivo de Aprendizaje
- Dominar pandas para manipulaciÃ³n de series de tiempo.
- Identificar patrones, correlaciones y anomalÃ­as en datos de proceso.
- Producir visualizaciones interpretables para ingenieros y operadores.
- Entender quÃ© variables "mueven la aguja" en turbiedad del espesador.

### Entregable Concreto
- `notebooks/01_eda.ipynb` completado con las **5 figuras definitorias** del proyecto:
  - Fig 1: Timeline turbiedad limpia vs medida + bandas + eventos + rÃ©gimen manual.
  - Fig 2: Episodios de eventos (duraciÃ³n vs severidad, coloreados por CLAY/UF).
  - Fig 3: Torque vs Yield Stress y Torque vs Cp (diagnÃ³stico de reologÃ­a).
  - Fig 4: Error del sensor de turbiedad (medida âˆ’ limpia) â€” distribuciÃ³n y series.
  - Fig 5: Vista de trade-off de eficiencia (recuperaciÃ³n de agua vs calidad).
- `reports/EDA_summary.md` con hallazgos clave en lenguaje de operador.

---

### MÃ³dulo 1.1 â€” pandas y Series de Tiempo

**Â¿Por quÃ© lo necesitas ahora?**
Tu dataset tiene 25.920 filas (90 dÃ­as Ã— 288 puntos/dÃ­a). Sin pandas fluido, cualquier anÃ¡lisis serÃ¡ doloroso.

**Concepto clave**: Un DataFrame de pandas es como una hoja de cÃ¡lculo inteligente que entiende fechas. El Ã­ndice temporal es tu "eje X" natural para datos de proceso.

#### Recursos de Estudio (30â€“45 min)
| Recurso | CapÃ­tulo/SecciÃ³n | Enfoque |
|---------|-----------------|---------|
| [Pandas Getting Started](https://pandas.pydata.org/docs/getting_started/intro_tutorials/) | Tutoriales 1â€“4 | Leer y ejecutar |
| *Python for Data Analysis*, Wes McKinney (O'Reilly) | Cap. 5 y 10 | Series temporales |
| [Real Python â€” Pandas DataFrames](https://realpython.com/pandas-dataframe/) | Secciones 1â€“3 | Referencia prÃ¡ctica |
| YouTube: [Corey Schafer â€” Pandas Series](https://www.youtube.com/watch?v=zmdjNSmRXF4) | Video completo | Visual y claro |

#### PrÃ¡ctica (2h)

**Ejercicio 1.1.1 â€” Carga y exploraciÃ³n bÃ¡sica** (30 min)
```python
# Sin copiar este cÃ³digo: escrÃ­belo tÃº mismo en el notebook.
# Objetivos:
# 1. Carga el parquet con pd.read_parquet()
# 2. Imprime shape, dtypes, primeras 10 filas
# 3. Verifica que el Ã­ndice es datetime
# 4. Reporta: Â¿cuÃ¡ntos NaN hay por columna? (usa .isnull().sum())
# 5. Â¿CuÃ¡l es el rango temporal exacto del dataset?
```

**Ejercicio 1.1.2 â€” Resample y estadÃ­sticas horarias** (45 min)
```python
# Sin copiar este cÃ³digo: escrÃ­belo tÃº mismo.
# 1. Crea df_hourly = df.resample('1h').mean()
# 2. Calcula media, std, min, max de Overflow_Turb_NTU_clean por hora del dÃ­a
# 3. Â¿A quÃ© hora del dÃ­a hay mÃ¡s eventos de turbiedad alta?
# AnalogÃ­a: es como calcular la ley de cabeza promedio por turno de 8h
```

**Ejercicio 1.1.3 â€” Filtrado por rÃ©gimen** (45 min)
```python
# Sin copiar: implemÃ©ntalo tÃº.
# 1. Separa los datos en tres DataFrames: df_normal, df_clay, df_uf
# 2. Para cada uno calcula: turbiedad promedio, tasa de eventos, torque promedio
# 3. Crea una tabla comparativa con pd.concat() o un dict
# Pregunta guÃ­a: Â¿Los eventos CLAY y UF son distinguibles solo con turbiedad?
```

**DesafÃ­o sin IA** (opcional, si terminas antes):
- Â¿Existe correlaciÃ³n entre el dÃ­a de la semana y la frecuencia de eventos?
  Pista: `df.index.dayofweek`

#### VerificaciÃ³n de Aprendizaje
1. Â¿CÃ³mo filtras filas de un DataFrame donde `Overflow_Turb_NTU_clean > 100`?
2. Â¿QuÃ© diferencia hay entre `.loc[]` y `.iloc[]`?
3. Â¿Por quÃ© hacer `resample('1h').mean()` en lugar de simplemente `.groupby()`?

**Lo logrÃ© si...**
- [ ] Puedo cargar, explorar y describir el dataset sin consultar notas.
- [ ] Entiendo quÃ© columna es "ground truth" y cuÃ¡l tiene fallas instrumentales.
- [ ] Produje al menos una tabla de estadÃ­sticas por rÃ©gimen (NORMAL/CLAY/UF).

---

### MÃ³dulo 1.2 â€” VisualizaciÃ³n con matplotlib y seaborn

**AnalogÃ­a minera**: Un buen grÃ¡fico de proceso es como un diagrama de flujo: comunica en segundos lo que una tabla tarda minutos en revelar. Un operador no lee tablas de nÃºmeros durante una guardia.

#### Recursos de Estudio (30â€“45 min)
| Recurso | SecciÃ³n | Enfoque |
|---------|---------|---------|
| [Matplotlib Tutorials](https://matplotlib.org/stable/tutorials/index.html) | Introductory | Subplots, ejes duales |
| [Seaborn Gallery](https://seaborn.pydata.org/examples/index.html) | Distribuciones, heatmaps | Ver y replicar |
| *Storytelling with Data*, Cole Nussbaumer Knaflic | Cap. 2â€“3 | Principios de visualizaciÃ³n |
| YouTube: [Keith Galli â€” Matplotlib](https://www.youtube.com/watch?v=DAQNHzOcXBU) | Completo | PrÃ¡ctica |

#### PrÃ¡ctica (2h) â€” Figura 1 y Figura 4

**Figura 1: Timeline completo** (1h)
```
Objetivo visual:
- Eje superior: Overflow_Turb_NTU_clean (lÃ­nea azul) y Overflow_Turb_NTU (gris, semitransparente)
- Banda roja horizontal en 100 NTU (lÃ­mite de evento)
- Sombras de fondo: verde=NORMAL, naranja=CLAY, rojo=UF
- Sombras grises verticales: periodos de control MANUAL
- Marcadores: puntos donde target_event_30m = 1
Pista: usa ax.axhspan() para las bandas y ax.fill_between() para regÃ­menes
```

**Figura 4: Error del sensor** (1h)
```
Objetivo:
- Calcula error = Overflow_Turb_NTU - Overflow_Turb_NTU_clean
- Subplot 1: histograma del error (seaborn.histplot con kde=True)
- Subplot 2: error en el tiempo, coloreado por tipo de falla (spike, stuck, drift)
- Â¿CuÃ¡ndo el sensor subestima? Â¿CuÃ¡ndo sobreestima?
```

#### VerificaciÃ³n de Aprendizaje
1. Â¿CÃ³mo crear dos ejes Y en el mismo grÃ¡fico (eje dual)?
2. Â¿QuÃ© hace `ax.fill_between()` y para quÃ© sirve en datos de proceso?
3. Â¿CuÃ¡l es la diferencia entre un grÃ¡fico de dispersiÃ³n y uno de lÃ­nea para datos de tiempo?

**Lo logrÃ© si...**
- [ ] Produje la Figura 1 con todas las capas (turbiedad, bandas, regÃ­menes, eventos).
- [ ] Produje la Figura 4 con distribuciÃ³n e interpretaciÃ³n del error del sensor.
- [ ] Mis grÃ¡ficos tienen tÃ­tulos, etiquetas de ejes y leyenda.

---

### MÃ³dulo 1.3 â€” AnÃ¡lisis de CorrelaciÃ³n y Patrones

**AnalogÃ­a minera**: La correlaciÃ³n entre variables de proceso es como el metalurgista que sabe que cuando sube el pH, baja la recuperaciÃ³n de Cu. No es causalidad, pero es una seÃ±al de alarma.

#### Recursos de Estudio (30 min)
| Recurso | SecciÃ³n |
|---------|---------|
| [Pandas Correlation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) | DocumentaciÃ³n oficial |
| Seaborn `heatmap` + `pairplot` | [Gallery](https://seaborn.pydata.org/examples/index.html) |
| *Hands-On ML*, AurÃ©lien GÃ©ron | Cap. 2 (EDA section) | AnÃ¡lisis de correlaciÃ³n |

#### PrÃ¡ctica (1h30min)

**Figura 3: Torque vs ReologÃ­a** (45 min)
```
Objetivo:
- Scatter: Torque_kNm vs UF_YieldStress_Pa, coloreado por Regime
- LÃ­nea de tendencia (np.polyfit o seaborn.regplot por rÃ©gimen)
- AnotaciÃ³n: "Â¿El torque es un proxy vÃ¡lido del Yield Stress?"
- Segundo scatter: Torque_kNm vs Cp_pct
```

**Heatmap de correlaciones** (45 min)
```
Objetivo:
- Calcula matriz de correlaciÃ³n de las variables numÃ©ricas clave
- Visualiza con seaborn.heatmap (annot=True, cmap='coolwarm')
- Identifica: Â¿quÃ© variables estÃ¡n mÃ¡s correlacionadas con Overflow_Turb_NTU_clean?
- Reporta top 5 correlaciones en EDA_summary.md
```

**Lo logrÃ© si...**
- [ ] IdentifiquÃ© las 5 variables mÃ¡s correlacionadas con la turbiedad limpia.
- [ ] Produje la Figura 3 con interpretaciÃ³n escrita.
- [ ] Puedo explicar por quÃ© correlaciÃ³n alta no implica que una variable cause la otra.

---

### RÃºbrica de AutoevaluaciÃ³n â€” Etapa 1

| Hito | Criterio de Ã‰xito | BÃ¡sico | Intermedio | Avanzado |
|------|-----------------|--------|------------|----------|
| Carga y exploraciÃ³n | DataFrame cargado, tipos correctos | CarguÃ© el archivo | IdentifiquÃ© NaN y outliers | AutomaticÃ© el reporte con funciÃ³n |
| Figura 1 | Timeline completo con capas | Una lÃ­nea de turbiedad | Bandas y regÃ­menes | Interactivo con plotly |
| Figura 3 | Torque vs reologÃ­a | Scatter bÃ¡sico | LÃ­neas de tendencia por rÃ©gimen | Modelo lineal y RÂ² reportado |
| Figura 4 | Error del sensor | Histograma simple | DistribuciÃ³n + serie temporal | CuantifiquÃ© fallas por tipo |
| EDA Summary | Hallazgos escritos | 3 observaciones | 5 con implicaciones operativas | Draft de narrativa tipo informe |

---

## ETAPA 2 â€” Salud de Sensores (Sensor Health Module)

> **AnalogÃ­a minera**: Un operador experimentado sabe cuÃ¡ndo el pH-metro estÃ¡ "loco" sin necesidad de un algoritmo. Tu objetivo es *codificar ese conocimiento* para que el sistema lo detecte automÃ¡ticamente.

### Objetivo de Aprendizaje
- Implementar detecciÃ³n de fallas instrumentales con reglas basadas en dominio.
- Generar flags de confianza (`conf_turbidity`, etc.) por tag.
- Comparar alertas con y sin el mÃ³dulo de salud para demostrar su valor.

### Entregable Concreto
- `src/sensor_health.py` â€” mÃ³dulo independiente con funciones de detecciÃ³n.
- `notebooks/02_sensor_health.ipynb` â€” anÃ¡lisis y validaciÃ³n del mÃ³dulo.
- Columna `turb_fault_flag` en el dataset procesado.

---

### MÃ³dulo 2.1 â€” Tipos de Fallas Instrumentales

**TeorÃ­a (30 min)**

Las fallas de sensores en plantas mineras siguen patrones reconocibles:

| Tipo de Falla | DescripciÃ³n | SeÃ±al en Datos | Ejemplo en Espesador |
|--------------|-------------|---------------|---------------------|
| **Spike** | Valor aberrante aislado | Pico puntual muy alejado de vecinos | Turbiedad salta a 9999 NTU por 5 min |
| **Stuck/Flatline** | Sensor congelado | Varianza cero en ventana temporal | pH = 7.43 exacto por 2 horas |
| **Drift** | DesviaciÃ³n gradual | Tendencia sin respuesta al proceso | Turbiedad sube 0.5 NTU/hora sin causa |
| **Missing** | Dato ausente | NaN | PÃ©rdida de comunicaciÃ³n SCADA |
| **Intermitente** | Alterna entre bueno y malo | Saltos entre valor real y cero/constante | Sensor de nivel con falla de conexiÃ³n |

**Recursos de Estudio**
| Recurso | Enfoque |
|---------|---------|
| [Pandas Rolling Window](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html) | Para cÃ¡lculos en ventana |
| ArtÃ­culo: *"Sensor Fault Detection in Industrial Processes"* â€” buscar en Google Scholar | Fundamentos |
| DocumentaciÃ³n de `Overflow_Turb_NTU` en `docs/02_data_dictionary.md` | QuÃ© fallas estÃ¡n simuladas |

---

### MÃ³dulo 2.2 â€” DetecciÃ³n Basada en Reglas

#### PrÃ¡ctica (2h30min)

**Ejercicio 2.2.1 â€” DetecciÃ³n de spikes** (45 min)
```python
# Implementar tÃº mismo en src/sensor_health.py:
# Un spike es un punto donde |valor - mediana_mÃ³vil| > k * mad_mÃ³vil
# donde MAD = Median Absolute Deviation (mÃ¡s robusto que std)
# ParÃ¡metros sugeridos: ventana=12 puntos (1h), k=5
# Devuelve: Serie booleana con True donde hay spike

def detect_spikes(series, window=12, k=5):
    """
    Detecta spikes por distancia a mediana mÃ³vil normalizada por MAD.
    AnalogÃ­a: es como el operador que descarta lecturas "que no tienen sentido"
    porque el valor anterior/siguiente son normales.
    """
    # Tu implementaciÃ³n aquÃ­
    pass
```

**Ejercicio 2.2.2 â€” DetecciÃ³n de flatlines** (45 min)
```python
# Un flatline es una ventana donde la std es prÃ¡cticamente cero
# ParÃ¡metros: ventana=6 puntos (30 min), umbral_std=0.01
# Cuidado: en el espesador, turbiedad PUEDE ser estable en condiciÃ³n normal.
# El criterio debe ser: std muy baja Y la variable deberÃ­a tener variaciÃ³n natural.

def detect_flatline(series, window=6, std_threshold=0.01):
    """
    Detecta periodos donde el sensor reporta variaciÃ³n nula.
    Trampa comÃºn: no confundir proceso estable con sensor congelado.
    SoluciÃ³n: comparar con otra variable que deberÃ­a co-variar.
    """
    pass
```

**Ejercicio 2.2.3 â€” Score de confianza compuesto** (1h)
```python
# Combina los detectores anteriores en un score:
# conf = 1.0  -> sensor confiable
# conf = 0.5  -> sospechoso (revisar)
# conf = 0.0  -> falla confirmada

def compute_confidence(df, tag='Overflow_Turb_NTU'):
    """
    Devuelve Serie con conf en [0, 1] para el tag especificado.
    Usar reglas AND/OR para combinar detectores.
    """
    pass
```

**DesafÃ­o sin IA**:
- El dataset tiene `Overflow_Turb_NTU_clean` como ground truth.
- EvalÃºa tu detector calculando: Â¿cuÃ¡ntas fallas reales detecta? Â¿cuÃ¡ntas falsas alarmas genera?
- Esto te anticipa el concepto de Precision/Recall de la Etapa 5.

#### VerificaciÃ³n de Aprendizaje
1. Â¿Por quÃ© usar la mediana en lugar de la media para detectar outliers?
2. Â¿QuÃ© problema tiene un umbral de `std < 0.01` para detectar flatlines en todas las variables por igual?
3. Â¿CÃ³mo afecta un spike no detectado a un modelo ML entrenado con esa variable?

**Lo logrÃ© si...**
- [ ] `sensor_health.py` tiene al menos 3 funciones de detecciÃ³n independientes.
- [ ] Puedo aplicar el mÃ³dulo al dataset real y obtener flags por columna.
- [ ] CuantifiquÃ© precision y recall de mi detector contra el ground truth del simulador.

---

### MÃ³dulo 2.3 â€” Para Profundizar (Opcional)

> **Si tienes tiempo**: Los mÃ©todos estadÃ­sticos de detecciÃ³n de anomalÃ­as en series temporales son un campo activo. AquÃ­ hay un nivel mÃ¡s:

- **Isolation Forest para anomalÃ­as multivariadas**: cuando la falla no es visible en una sola variable sino en la combinaciÃ³n de varias.
  - Recurso: `sklearn.ensemble.IsolationForest` â€” [documentaciÃ³n](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html)
- **Control Charts (SPC)**: el mÃ©todo industrial estÃ¡ndar. Los grÃ¡ficos de control EWMA (Exponentially Weighted Moving Average) son usados en plantas mineras.
  - Recurso: *Statistical Process Control*, Montgomery â€” Cap. 9.
- **Prophet para detecciÃ³n de drift**: el modelo de Meta para series de tiempo puede modelar la tendencia esperada y detectar desvÃ­os.

---

### RÃºbrica de AutoevaluaciÃ³n â€” Etapa 2

| Hito | BÃ¡sico | Intermedio | Avanzado |
|------|--------|------------|----------|
| DetecciÃ³n de spikes | Umbral simple (> 3Ïƒ) | MAD robusto con ventana mÃ³vil | ComparaciÃ³n cruzada entre sensores |
| DetecciÃ³n de flatlines | std < umbral | std < umbral + verificaciÃ³n de co-varianza | Longitud mÃ­nima del evento |
| Score de confianza | Flag binario | Score 0â€“1 continuo | Score con nivel de confianza estadÃ­stico |
| ValidaciÃ³n | InspecciÃ³n visual | Precision/Recall vs ground truth | Curva ROC del detector |
| MÃ³dulo `sensor_health.py` | Funciones sueltas | MÃ³dulo importable y testeado | Con docstrings y tests unitarios |

---

## ETAPA 3 â€” VisualizaciÃ³n Operacional (Power BI)

> **AnalogÃ­a minera**: El dashboard de Power BI es el "sala de control" digital. Si el panel del operador no muestra la informaciÃ³n correcta, el mejor modelo del mundo es inÃºtil.

### Objetivo de Aprendizaje
- Construir un dashboard operacional en Power BI Desktop.
- Conectar Power BI con datos exportados desde Python.
- Crear KPIs visuales alineados con los objetivos del espesador.

### Entregable Concreto
- `dashboards/TWS_operacional.pbix` â€” archivo Power BI Desktop.
- `data/processed/for_powerbi/` â€” carpeta con CSVs exportados desde Python.
- `reports/dashboard_guide.md` â€” guÃ­a de uso del dashboard.

---

### MÃ³dulo 3.1 â€” Exportar Datos desde Python para Power BI

**Por quÃ© hacerlo bien desde el principio**: Power BI tiene un lÃ­mite de actualizaciÃ³n de datos. Si exportas CSVs con estructura limpia (una fila = un punto en el tiempo, columnas bien nombradas), el dashboard se actualiza sin problemas.

#### PrÃ¡ctica (1h30min)

**Ejercicio 3.1.1 â€” Preparar tablas para BI**
```python
# En un script src/export_for_bi.py (escrÃ­belo tÃº):
# 1. Cargar dataset procesado
# 2. Exportar tabla_operacion.csv:
#    Columnas: Timestamp, Regime, Turb_clean, Turb_measured, conf_turbidity,
#              event_now, target_event_30m, Torque_kNm, Underflow_Density_gpl
# 3. Exportar tabla_eventos.csv:
#    Una fila por evento de turbiedad (inicio, fin, duraciÃ³n, mÃ¡x_NTU, regime)
# 4. Exportar tabla_kpis_diarios.csv:
#    Una fila por dÃ­a con: fracciÃ³n_verde, fracciÃ³n_degradado, fracciÃ³n_evento,
#    fracciÃ³n_manual, agua_recuperada_proxy
```

---

### MÃ³dulo 3.2 â€” ConstrucciÃ³n del Dashboard

**Recursos de Estudio**
| Recurso | Enfoque |
|---------|---------|
| [Power BI Desktop â€” Getting Started](https://learn.microsoft.com/en-us/power-bi/fundamentals/desktop-getting-started) | Tutorial oficial |
| YouTube: [Guy in a Cube](https://www.youtube.com/@GuyInACube) | Canal referencia en Power BI |
| YouTube: [Avi Singh Power BI](https://www.youtube.com/@LearnPowerBI) | Visualizaciones avanzadas |

#### PrÃ¡ctica (3h â€” distribuir en varios dÃ­as)

**Vista 1 â€” Panel de Estado Actual**
```
DiseÃ±o sugerido (dibuja en papel antes de abrir Power BI):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ESTADO ACTUAL DEL ESPESADOR                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Turbiedadâ”‚ RÃ©gimen  â”‚ Alarma   â”‚ Conf. Sensor      â”‚
â”‚ 47 NTU   â”‚ CLAY     â”‚ ğŸŸ¡ PREV â”‚ 0.82              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Timeline Ãºltimas 24h (turbiedad + lÃ­mites)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  KPIs diarios: % Verde | % Degradado | % Evento    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Vista 2 â€” Salud de Sensores**
- Tabla de tags con semÃ¡foro (verde/amarillo/rojo) segÃºn `conf_xxx`.
- GrÃ¡fico de Ãºltimas lecturas por sensor con banda de operaciÃ³n normal.

**Vista 3 â€” HistÃ³rico de Eventos**
- Tabla de eventos: inicio, fin, duraciÃ³n, mÃ¡ximo NTU, rÃ©gimen.
- GrÃ¡fico de barras: eventos por semana y por rÃ©gimen.

#### VerificaciÃ³n de Aprendizaje
1. Â¿CÃ³mo crear una medida DAX que calcule el porcentaje de tiempo en estado VERDE?
2. Â¿QuÃ© diferencia hay entre un visual de "Tarjeta" y uno de "KPI" en Power BI?
3. Â¿CÃ³mo configurar una actualizaciÃ³n automÃ¡tica cuando cambia el CSV de origen?

**Lo logrÃ© si...**
- [ ] El dashboard tiene al menos 3 vistas navegables.
- [ ] Los KPIs operacionales son visibles sin scroll en la vista principal.
- [ ] Puedo actualizar el dashboard exportando nuevos CSVs desde Python.

---

## ETAPA 4 â€” Feature Engineering Minero

> **AnalogÃ­a minera**: El feature engineering es como la preparaciÃ³n de muestra antes del anÃ¡lisis. Si molieras mal la muestra, aunque tengas el mejor ICP-MS del mundo, los resultados serÃ¡n malos. Los features son la preparaciÃ³n de tu "muestra" para el modelo.

### Objetivo de Aprendizaje
- Crear features basadas en conocimiento del proceso (lag features, rolling stats, derivadas).
- Transformar variables de dominio en seÃ±ales Ãºtiles para el modelo.
- Documentar cada feature con su justificaciÃ³n metalÃºrgica.

### Entregable Concreto
- `src/feature_engineering.py` â€” mÃ³dulo con funciÃ³n `build_features(df)`.
- `notebooks/03_feature_engineering.ipynb` â€” anÃ¡lisis de importancia de features.
- `docs/feature_catalog.md` â€” catÃ¡logo con cada feature, su fÃ³rmula y justificaciÃ³n.

---

### MÃ³dulo 4.1 â€” Features Temporales (Lag y Rolling)

**TeorÃ­a (30 min)**

El horizonte de predicciÃ³n es 30 minutos (6 puntos a 5 min). Eso significa:
- El modelo ve datos hasta el momento `t`.
- Predice si habrÃ¡ evento en `[t+6, t+6+4]` (ventana de evento sostenido).
- Los features mÃ¡s Ãºtiles son los que capturan la *tendencia reciente*.

**Tipos de features temporales:**

| Feature | FÃ³rmula | JustificaciÃ³n Minera |
|---------|---------|---------------------|
| Lag-N | `x(t-N)` | "Â¿CÃ³mo estaba la turbiedad hace 30 min?" |
| Rolling Mean | `mean(x[t-N:t])` | "Tendencia de la Ãºltima hora" |
| Rolling Std | `std(x[t-N:t])` | "Â¿EstÃ¡ el proceso inestable?" |
| Diferencia | `x(t) - x(t-1)` | "Â¿EstÃ¡ subiendo o bajando?" |
| AceleraciÃ³n | `Î”x(t) - Î”x(t-1)` | "Â¿EstÃ¡ acelerando el cambio?" |
| Rolling Max | `max(x[t-N:t])` | "Â¿Hubo un pico reciente?" |

#### Recursos de Estudio
| Recurso | Enfoque |
|---------|---------|
| [Pandas shift()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html) | Para lags |
| [Pandas rolling()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html) | Para ventanas |
| ArtÃ­culo: *"Feature Engineering for Time Series Classification"* | Google Scholar |

#### PrÃ¡ctica (2h)

**Ejercicio 4.1.1 â€” Implementar build_features()** (1h30min)
```python
# En src/feature_engineering.py, implementa:
# Cada feature debe tener un comentario con su justificaciÃ³n de proceso

FEATURE_CONFIG = {
    # Variables base para crear features
    'rolling_vars': [
        'Overflow_Turb_NTU',       # Turbiedad medida (con fallas)
        'FeedFlowrate_m3h',        # Caudal de alimentaciÃ³n
        'Torque_kNm',              # Torque del rastrillos
        'Floc_gpt',                # Dosis de floculante
        'Underflow_Density_gpl',   # Densidad de underflow
    ],
    'windows': [2, 6, 12, 24],    # 10min, 30min, 1h, 2h
    'lags': [1, 2, 6, 12],        # 5min, 10min, 30min, 1h
}

def build_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Construye features para el modelo de predicciÃ³n de turbiedad.
    Returns: DataFrame con features nuevas + columnas originales.
    """
    pass
```

**Ejercicio 4.1.2 â€” Features derivadas de dominio** (30 min)
```python
# Features que requieren conocimiento metalÃºrgico:
# 1. Stress_Index: combinaciÃ³n de fines, carga, variabilidad, UF (ya en simulador)
# 2. Turb_trend: pendiente de regresiÃ³n lineal en Ãºltimos 6 puntos
#    Pista: usa np.polyfit(range(6), valores, deg=1)[0]
# 3. Time_above_50NTU: minutos consecutivos sobre 50 NTU
# 4. Floc_efficiency: turbiedad / dosis_floculante (ratio inverso de eficiencia)
# 5. Torque_normalized: Torque_kNm / FeedFlowrate_m3h (torque por unidad de caudal)
```

**DesafÃ­o sin IA**:
- Â¿CuÃ¡ntas features terminas creando? Â¿CuÃ¡les son las 10 mÃ¡s correlacionadas con `target_event_30m`?
- Pista: Calcula la correlaciÃ³n y ordena de mayor a menor.

#### VerificaciÃ³n de Aprendizaje
1. Â¿Por quÃ© es importante que los features de lag/rolling se calculen **sin incluir el futuro** (sin data leakage)?
2. Â¿QuÃ© pasa si entrenas un modelo con un feature que incluye la variable target en su cÃ¡lculo?
3. Â¿CÃ³mo se detecta el "data leakage" en un pipeline de ML?

**Lo logrÃ© si...**
- [ ] `build_features()` genera al menos 30 features documentadas.
- [ ] NingÃºn feature incluye informaciÃ³n del futuro respecto a `t`.
- [ ] El catÃ¡logo de features tiene justificaciÃ³n de proceso para cada grupo.

---

### MÃ³dulo 4.2 â€” SelecciÃ³n de Features y VisualizaciÃ³n de Importancia

**TeorÃ­a (30 min)**

Con 30+ features, no todas son Ãºtiles. Dos problemas comunes:
1. **Multicolinealidad**: features muy correlacionadas entre sÃ­ confunden al modelo.
2. **Ruido**: features con poca seÃ±al aumentan el tiempo de entrenamiento sin mejorar el modelo.

**Recursos de Estudio**
| Recurso | Enfoque |
|---------|---------|
| [Sklearn Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html) | MÃ©todos estadÃ­sticos |
| *Hands-On ML*, GÃ©ron | Cap. 4: regularizaciÃ³n y selecciÃ³n |

#### PrÃ¡ctica (1h30min)
```python
# 1. Calcula matriz de correlaciÃ³n de los features (no del target)
# 2. Identifica pares con correlaciÃ³n > 0.95 (candidatos a eliminar uno)
# 3. Usa SelectKBest con f_classif para ranking estadÃ­stico de features
# 4. Visualiza un heatmap de las top-20 features vs target
# Entregable: lista de features_finales.txt con las features seleccionadas
```

**Lo logrÃ© si...**
- [ ] IdentifiquÃ© y eliminÃ© features redundantes (correlaciÃ³n > 0.95 entre sÃ­).
- [ ] Tengo una lista priorizada de los top-20 features para el modelo.
- [ ] Entiendo por quÃ© "mÃ¡s features" no siempre es mejor.

---

### RÃºbrica de AutoevaluaciÃ³n â€” Etapa 4

| Hito | BÃ¡sico | Intermedio | Avanzado |
|------|--------|------------|----------|
| Features temporales | Lags simples | Rolling + diferencias | RegresiÃ³n local (tendencia) |
| Features de dominio | 2â€“3 ratios simples | 5+ con justificaciÃ³n | Validadas con experto o literatura |
| CatÃ¡logo | Lista de nombres | DescripciÃ³n + fÃ³rmula | JustificaciÃ³n operativa + ejemplo |
| SelecciÃ³n | Sin selecciÃ³n | CorrelaciÃ³n con target | SelectKBest + visualizaciÃ³n |
| MÃ³dulo `feature_engineering.py` | Script secuencial | FunciÃ³n reutilizable | Pipeline sklearn compatible |

---

## ETAPA 5 â€” Modelado Predictivo Base

> **AnalogÃ­a minera**: El modelo de ML es como el ensayo metalÃºrgico a escala piloto. Antes de instalar equipos nuevos en la planta, pruebas en laboratorio. AquÃ­ tu "laboratorio" es el conjunto de datos histÃ³ricos.

### Objetivo de Aprendizaje
- Implementar clasificadores para `target_event_30m` con divisiÃ³n temporal correcta.
- Evaluar con mÃ©tricas operacionales (no solo accuracy).
- Comparar al menos 2 modelos y seleccionar el mejor justificadamente.

### Entregable Concreto
- `notebooks/04_modeling.ipynb` â€” entrenamiento, evaluaciÃ³n y comparaciÃ³n.
- `models/baseline_lgbm.pkl` â€” modelo serializado.
- `reports/model_card.md` â€” ficha tÃ©cnica del modelo seleccionado.

---

### MÃ³dulo 5.1 â€” DivisiÃ³n Temporal y MÃ©tricas Operacionales

**ADVERTENCIA CRÃTICA â€” La trampa mÃ¡s comÃºn en ML con series de tiempo**

> Si usas `train_test_split` aleatorio en datos temporales, estÃ¡s "mirando el futuro" durante el entrenamiento. Esto da mÃ©tricas falsas y un modelo que falla en producciÃ³n.
>
> **La regla**: en datos de proceso, el conjunto de entrenamiento siempre precede al de prueba en el tiempo.

```
Correcto:    |---Train (60 dÃ­as)---|--Val (15 dÃ­as)--|--Test (15 dÃ­as)--|
Incorrecto:  Mezcla aleatoria de todos los puntos del tiempo
```

**MÃ©tricas operacionales para este proyecto**

| MÃ©trica | FÃ³rmula | InterpretaciÃ³n Minera |
|---------|---------|----------------------|
| **Recall** | TP/(TP+FN) | % de crisis que el modelo detectÃ³. Una crisis no detectada puede contaminar el proceso. |
| **Precision** | TP/(TP+FP) | % de alarmas que fueron reales. Muchas falsas alarmas = operadores ignoran el sistema. |
| **F1-Score** | 2Â·PÂ·R/(P+R) | Balance entre los dos anteriores. |
| **Lead Time** | media(t_alarma âˆ’ t_inicio_evento) | Â¿Con cuÃ¡ntos minutos de anticipaciÃ³n avisa? Meta: â‰¥ 20 min. |
| **False Alarms/Day** | FP / dÃ­as_totales | Tolerancia del operador: mÃ¡ximo 2â€“3 por turno. |

**Recursos de Estudio**
| Recurso | Enfoque |
|---------|---------|
| *Hands-On ML*, GÃ©ron | Cap. 3: clasificaciÃ³n y mÃ©tricas |
| [Sklearn metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) | classification_report, confusion_matrix |
| LightGBM: [documentaciÃ³n oficial](https://lightgbm.readthedocs.io/) | InstalaciÃ³n y parÃ¡metros |
| YouTube: [StatQuest â€” ROC Curves](https://www.youtube.com/watch?v=4jRBRDbJemM) | Visual y claro |

#### PrÃ¡ctica (3h â€” distribuir en varios dÃ­as)

**Ejercicio 5.1.1 â€” DivisiÃ³n temporal** (30 min)
```python
# En notebooks/04_modeling.ipynb, implementa:
# Estrategia: 60 dÃ­as train, 15 dÃ­as val, 15 dÃ­as test
# SIN usar train_test_split aleatoriamente

def temporal_split(df, train_days=60, val_days=15):
    """
    Divide el DataFrame por fechas, no aleatoriamente.
    Verifica que no hay solapamiento entre conjuntos.
    """
    pass

# DespuÃ©s de dividir:
# Imprime la distribuciÃ³n de target_event_30m en cada conjunto
# Â¿Es similar en train, val y test? Â¿Por quÃ© o por quÃ© no?
```

**Ejercicio 5.1.2 â€” Modelo baseline: Logistic Regression** (45 min)
```python
# 1. Entrena LogisticRegression con los top-20 features de la Etapa 4
# 2. Imprime classification_report en val y test
# 3. Grafica la matriz de confusiÃ³n (usa seaborn.heatmap)
# 4. Calcula: Â¿cuÃ¡ntas falsas alarmas por dÃ­a? Â¿cuÃ¡ntos eventos no detectados?
# 5. Registra resultados en una tabla de comparaciÃ³n
```

**Ejercicio 5.1.3 â€” Modelo mejorado: LightGBM** (1h30min)
```python
# 1. Instala lightgbm si no estÃ¡: pip install lightgbm
# 2. Entrena LGBMClassifier con parÃ¡metros por defecto
# 3. Ajusta scale_pos_weight para compensar el desbalance de clases
#    (los eventos son ~5% de los datos; sin compensar, el modelo ignorarÃ¡ los eventos)
#    scale_pos_weight = n_negatives / n_positives
# 4. Compara mÃ©tricas con logistic regression
# 5. Grafica curva ROC para ambos modelos en el mismo grÃ¡fico
```

**DesafÃ­o sin IA**:
- Â¿QuÃ© umbral de probabilidad usarÃ­as para la clasificaciÃ³n final?
- El umbral por defecto es 0.5, pero para este problema, Â¿deberÃ­a ser mayor o menor?
- Pista: piensa en quÃ© es peor, una alarma falsa o una crisis no detectada.

#### VerificaciÃ³n de Aprendizaje
1. Â¿Por quÃ© `accuracy` es una mÃ©trica engaÃ±osa cuando el 95% de los datos son negativos?
2. Â¿QuÃ© es la curva ROC y cÃ³mo se interpreta el Ã¡rea bajo la curva (AUC)?
3. Â¿Por quÃ© necesitas un conjunto de validaciÃ³n ademÃ¡s del de test?

**Lo logrÃ© si...**
- [ ] ImplementÃ© divisiÃ³n temporal (sin mezcla aleatoria) y lo entiendo.
- [ ] Tengo al menos 2 modelos comparados con las mismas mÃ©tricas operacionales.
- [ ] Puedo justificar la elecciÃ³n del umbral de clasificaciÃ³n en tÃ©rminos operativos.

---

### MÃ³dulo 5.2 â€” Para Profundizar (Opcional)

> **Si tienes tiempo**: el modelo base puede mejorarse de varias formas.

- **Cross-validation temporal (TimeSeriesSplit)**: en lugar de una sola divisiÃ³n, usa 5 divisiones temporales para estimaciones mÃ¡s robustas.
  - Recurso: `sklearn.model_selection.TimeSeriesSplit`
- **Optuna para optimizaciÃ³n de hiperparÃ¡metros**: bÃºsqueda automÃ¡tica de los mejores parÃ¡metros de LightGBM.
  - Recurso: [Optuna documentation](https://optuna.org/)
- **CalibraciÃ³n de probabilidades**: los modelos de Ã¡rbol suelen estar mal calibrados. `CalibratedClassifierCV` mejora las probabilidades predichas.
- **Modelos de secuencia**: si los resultados del modelo base son buenos, considera LSTM o Temporal Fusion Transformer para capturar dependencias temporales mÃ¡s largas.

---

## ETAPA 6 â€” Interpretabilidad y AnÃ¡lisis de Errores

> **AnalogÃ­a minera**: Si el modelo dice "el espesador va a tener una crisis", el operador pregunta "Â¿por quÃ©?". Si no tienes respuesta, no confiarÃ¡ en el sistema. SHAP es la respuesta a ese "Â¿por quÃ©?".

### Objetivo de Aprendizaje
- Implementar anÃ¡lisis SHAP para el modelo seleccionado.
- Identificar cuÃ¡les features son mÃ¡s importantes para cada predicciÃ³n.
- Analizar los errores del modelo (falsos positivos y falsos negativos) para mejorar o documentar limitaciones.

### Entregable Concreto
- `notebooks/05_interpretability.ipynb` â€” anÃ¡lisis SHAP completo.
- `reports/model_errors.md` â€” casos representativos de errores con explicaciÃ³n.

---

### MÃ³dulo 6.1 â€” SHAP Values

**TeorÃ­a (45 min)**

SHAP (SHapley Additive exPlanations) responde: "Â¿CuÃ¡nto contribuyÃ³ cada feature a esta predicciÃ³n especÃ­fica?"

**AnalogÃ­a minera**: Es como la auditorÃ­a de una planta. Al final del mes, calculas cuÃ¡nto aportÃ³ cada etapa del proceso (chancado, molienda, flotaciÃ³n) a la pÃ©rdida de Cu. SHAP hace lo mismo con el modelo.

- **SHAP global**: importancia promedio de cada feature en todas las predicciones.
- **SHAP local**: explicaciÃ³n de una predicciÃ³n individual.
- **SHAP summary plot**: visualiza la distribuciÃ³n de importancias para todas las features.

**Recursos de Estudio**
| Recurso | Enfoque |
|---------|---------|
| [SHAP Documentation](https://shap.readthedocs.io/) | Tutorial oficial |
| *Interpretable Machine Learning*, Christoph Molnar | Cap. 9 (gratis en lÃ­nea) |
| YouTube: [Weights & Biases â€” SHAP](https://www.youtube.com/watch?v=ngOBhhINWb8) | Visual y prÃ¡ctico |

#### PrÃ¡ctica (2h)

**Ejercicio 6.1.1 â€” Summary Plot** (45 min)
```python
# import shap
# explainer = shap.TreeExplainer(modelo_lgbm)
# shap_values = explainer(X_test)
# shap.summary_plot(shap_values, X_test, max_display=20)
# Interpreta: Â¿quÃ© feature tiene mayor impacto promedio?
# Â¿Los valores altos de turbiedad_rolling_mean_12 aumentan o disminuyen el riesgo?
```

**Ejercicio 6.1.2 â€” Waterfall Plot para un Evento Real** (45 min)
```python
# Selecciona un verdadero positivo (TP): el modelo predijo evento y ocurriÃ³
# Muestra el waterfall plot de SHAP para ese punto
# Interpreta: "En este punto, la turbiedad media de la Ãºltima hora (47 NTU)
# aumentÃ³ la probabilidad de evento en +0.23"
# Repite para un falso negativo (FN): Â¿por quÃ© el modelo no lo detectÃ³?
```

**Ejercicio 6.1.3 â€” AnÃ¡lisis de Errores** (30 min)
```python
# Clasifica los errores del modelo:
# FP: Â¿tienden a ocurrir en rÃ©gimen CLAY o UF?
# FN: Â¿el proceso tenÃ­a alguna seÃ±al inusual que el modelo ignorÃ³?
# Documenta 2 casos representativos en reports/model_errors.md
```

**Lo logrÃ© si...**
- [ ] Puedo explicar por quÃ© el modelo predijo "evento" en un punto especÃ­fico usando SHAP.
- [ ] IdentifiquÃ© las 3 features mÃ¡s importantes globalmente y tienen sentido operativo.
- [ ] DocumentÃ© al menos un caso de FP y uno de FN con contexto del proceso.

---

### MÃ³dulo 6.2 â€” Para Profundizar (Opcional)
- **LIME (Local Interpretable Model-agnostic Explanations)**: alternativa a SHAP para explicaciones locales.
- **Partial Dependence Plots (PDP)**: visualiza el efecto marginal de una feature manteniendo las demÃ¡s constantes.
  - Recurso: `sklearn.inspection.PartialDependenceDisplay`
- **Monitoring del drift en producciÃ³n**: Â¿cÃ³mo detectar cuando la distribuciÃ³n de features cambia respecto a los datos de entrenamiento? `evidently` library.

---

## ETAPA 7 â€” Despliegue y Portafolio Final

> **AnalogÃ­a minera**: No basta con demostrar que el proceso funciona en laboratorio (notebook). Necesitas demostrar que puede operar en planta (API + dashboard). Un portafolio sin cÃ³digo desplegable es un informe de tesis, no un producto.

### Objetivo de Aprendizaje
- Empaquetar el modelo como API simple con FastAPI.
- Completar la documentaciÃ³n del repositorio.
- Preparar la "memoria de tÃ­tulo" como README y reporte tÃ©cnico.

### Entregable Concreto
- `api/main.py` â€” API con endpoint `/predict` (opcional pero recomendado).
- `README.md` â€” principal del repositorio, con badges, descripciÃ³n y ejemplos.
- `reports/memoria_titulo.md` â€” informe tÃ©cnico completo.
- Repositorio GitHub pÃºblico con commits limpios.

---

### MÃ³dulo 7.1 â€” API con FastAPI (Opcional, Alta Prioridad)

**Â¿Por quÃ© FastAPI?**
- MÃ¡s rÃ¡pido de aprender que Flask para principiantes.
- Genera documentaciÃ³n automÃ¡tica (Swagger UI).
- Un endpoint `/predict` que acepta JSON y devuelve predicciÃ³n + SHAP top-3 es lo que diferencia un portafolio de "notebook" de uno de "producto".

#### Recursos de Estudio
| Recurso | Enfoque |
|---------|---------|
| [FastAPI Tutorial](https://fastapi.tiangolo.com/tutorial/) | Primeros 5 capÃ­tulos |
| `joblib.dump` / `joblib.load` | Para serializar el modelo |

#### PrÃ¡ctica (2h)
```python
# api/main.py â€” escrÃ­belo tÃº:
# Endpoints:
#   GET  /health  -> {"status": "ok"}
#   POST /predict -> acepta JSON con Ãºltimas N lecturas del sensor
#                    devuelve {"prob_evento": 0.73, "alarma": true,
#                              "top_features": [{"name": "turb_roll_12", "shap": 0.31}]}

# Paso 1: Carga el modelo serializado con joblib
# Paso 2: Define el schema de entrada con Pydantic (FastAPI lo usa automÃ¡ticamente)
# Paso 3: Implementa la funciÃ³n de predicciÃ³n que:
#    - Recibe datos raw
#    - Aplica build_features()
#    - Predice con el modelo
#    - Calcula SHAP para los top-3 features
# Paso 4: Prueba con uvicorn y visita /docs para ver Swagger
```

**Lo logrÃ© si...**
- [ ] La API devuelve una predicciÃ³n real cuando le envÃ­o datos del dataset de test.
- [ ] La documentaciÃ³n Swagger describe el endpoint correctamente.
- [ ] Puedo conectar Power BI a la API (o al menos describir cÃ³mo hacerlo).

---

### MÃ³dulo 7.2 â€” Repositorio GitHub y DocumentaciÃ³n

**Estructura final del repositorio**
```
TWS_ESPESADOR/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/         # CI bÃ¡sico (opcional)
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py            # FastAPI app
â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”œâ”€â”€ bitacora/              # Decisiones de ingenierÃ­a (ya existe)
â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ TWS_operacional.pbix
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/         # Gitignored (generado)
â”‚   â””â”€â”€ for_powerbi/       # CSVs exportados
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ 00_overview.md     # Ya existe
â”‚   â”œâ”€â”€ feature_catalog.md # Nuevo
â”‚   â””â”€â”€ model_card.md      # Nuevo
â”œâ”€â”€ models/
â”‚   â””â”€â”€ baseline_lgbm.pkl  # Gitignored (generado)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_sensor_health.ipynb
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 04_modeling.ipynb
â”‚   â””â”€â”€ 05_interpretability.ipynb
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ EDA_summary.md
â”‚   â”œâ”€â”€ model_errors.md
â”‚   â””â”€â”€ memoria_titulo.md  # Informe final
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ simulate_fixed.py
â”‚   â”œâ”€â”€ quick_checks.py
â”‚   â”œâ”€â”€ sensor_health.py   # Nuevo
â”‚   â”œâ”€â”€ feature_engineering.py # Nuevo
â”‚   â””â”€â”€ export_for_bi.py   # Nuevo
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_sensor_health.py
â”‚   â””â”€â”€ test_features.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ CLAUDE.md
â”œâ”€â”€ README.md              # Renovar completamente
â””â”€â”€ requirements.txt
```

**Checklist del README.md**
- [ ] Badge de Python version y licencia.
- [ ] DescripciÃ³n del problema en 2 pÃ¡rrafos (contexto minero + soluciÃ³n ML).
- [ ] Diagrama de arquitectura del sistema (ASCII o imagen).
- [ ] Instrucciones de instalaciÃ³n y generaciÃ³n de datos.
- [ ] Tabla de resultados del modelo con mÃ©tricas operacionales.
- [ ] Screenshot del dashboard de Power BI.
- [ ] SecciÃ³n "PrÃ³ximos pasos" con mejoras identificadas.

---

### MÃ³dulo 7.3 â€” Informe TÃ©cnico (Memoria de TÃ­tulo)

**Estructura de `reports/memoria_titulo.md`**

```markdown
# Sistema de Monitoreo Predictivo para Espesador de Relaves
## DetecciÃ³n Temprana de Crisis de Turbiedad â€” Proyecto TWS_ESPESADOR

### 1. Resumen Ejecutivo (1 pÃ¡gina)
### 2. IntroducciÃ³n
   - Contexto: recuperaciÃ³n de agua en minerÃ­a del cobre
   - Problema: crisis de turbiedad y sus consecuencias
   - Objetivo y alcance del proyecto
### 3. Dataset SintÃ©tico
   - DiseÃ±o del simulador
   - ValidaciÃ³n KPI contra literatura
   - Limitaciones y supuestos
### 4. MetodologÃ­a
   - Pipeline de datos (sensor health â†’ features â†’ modelo)
   - Criterio de divisiÃ³n temporal
   - MÃ©tricas operacionales seleccionadas
### 5. Resultados
   - Modelo seleccionado y mÃ©tricas
   - AnÃ¡lisis SHAP e interpretabilidad
   - Casos de estudio (un CLAY, un UF)
### 6. Dashboard y Despliegue
   - Power BI y lÃ³gica de actualizaciÃ³n
   - API de predicciÃ³n (si aplica)
### 7. DiscusiÃ³n y Conclusiones
   - Aportes del proyecto
   - Limitaciones
   - Trabajo futuro
### ApÃ©ndices
   - CatÃ¡logo de features
   - ParÃ¡metros del modelo
   - GuÃ­a de uso del dashboard
```

**Lo logrÃ© si...**
- [ ] El repositorio es cloneable y reproducible por otra persona siguiendo el README.
- [ ] La memoria tiene introducciÃ³n, metodologÃ­a y resultados coherentes.
- [ ] El dashboard muestra datos reales del dataset generado.

---

## ENTREGABLES FINALES DEL PROYECTO

| Entregable | Archivo/UbicaciÃ³n | Estado |
|-----------|------------------|--------|
| Pipeline ETL con detecciÃ³n de fallas | `src/sensor_health.py` + `src/feature_engineering.py` | ğŸ”² |
| Dashboard Power BI | `dashboards/TWS_operacional.pbix` | ğŸ”² |
| Modelo predictivo interpretable | `models/baseline_lgbm.pkl` + `notebooks/05_interpretability.ipynb` | ğŸ”² |
| API de predicciÃ³n | `api/main.py` | ğŸ”² (opcional) |
| Repositorio GitHub documentado | PÃºblico, con README completo | ğŸ”² |
| Informe tipo memoria de tÃ­tulo | `reports/memoria_titulo.md` | ğŸ”² |

---

## BUENAS PRÃCTICAS DE GIT (recordatorio permanente)

```bash
# Flujo de trabajo diario recomendado:
git status                           # Ver quÃ© cambiÃ³
git add src/sensor_health.py         # Agregar archivos especÃ­ficos (no git add .)
git commit -m "feat: add flatline detector with std threshold"
# Formato de commit: tipo: descripciÃ³n breve
# Tipos: feat, fix, docs, refactor, test, chore
```

**Reglas bÃ¡sicas**
- Un commit = un cambio conceptual. No acumules una semana de trabajo en un commit.
- Nunca subas a GitHub: datos (`.parquet`), modelos (`.pkl`), credenciales (`.env`), o notebooks con output de celdas sensibles.
- El `.gitignore` ya existe: revÃ­salo y actualizalo cuando agregues nuevos tipos de archivos.

---

## TRAMPAS MENTALES â€” Errores Comunes de Principiantes

> Estos son los errores mÃ¡s frecuentes. LÃ©elos **ahora** y vuelve a leerlos cuando algo no funcione.

### Data Science

| Trampa | Consecuencia | SoluciÃ³n |
|--------|-------------|---------|
| Usar `train_test_split` aleatorio en series de tiempo | MÃ©tricas infladas, modelo inÃºtil en producciÃ³n | Siempre dividir por fecha |
| Escalar datos antes de dividir train/test | Data leakage: el scaler "vio" el test | Siempre fit en train, transform en train y test |
| Evaluar solo con accuracy en clases desbalanceadas | El modelo parece bueno prediciendo siempre "sin evento" | Usar recall, precision y F1 |
| Incluir la variable target en los features | El modelo "hace trampa" | Verificar que ningÃºn feature deriva del label |
| No documentar decisiones de modelado | Olvidar por quÃ© se tomaron decisiones | Usar `bitacora/` para cada experimento relevante |

### Python / ProgramaciÃ³n

| Trampa | Consecuencia | SoluciÃ³n |
|--------|-------------|---------|
| Hardcodear rutas absolutas (`C:/Matias/...`) | El cÃ³digo no funciona en otro computador | Usar `pathlib.Path` relativo al proyecto |
| Variables globales en notebooks | Estado imposible de reproducir | Usar funciones con parÃ¡metros explÃ­citos |
| No crear entorno virtual | Conflictos de dependencias | Siempre trabajar en `.venv` |
| Hacer `git add .` sin revisar | Subir archivos de datos, claves, basura | Hacer `git status` antes de cada commit |

### Power BI

| Trampa | Consecuencia | SoluciÃ³n |
|--------|-------------|---------|
| Conectar directamente al parquet | DifÃ­cil de actualizar con nuevos datos | Exportar CSVs desde Python con script |
| No documentar las medidas DAX | Dashboard no mantenible | Comentar cada medida DAX |
| Crear demasiadas pÃ¡ginas | Dashboard confuso para el operador | MÃ¡ximo 3 vistas bien diseÃ±adas |

---

## RECURSOS PERMANENTES

### Libros Clave (buscar versiones PDF o en biblioteca)
| Libro | Autor | Uso en este proyecto |
|-------|-------|---------------------|
| *Python for Data Analysis* (3rd ed.) | Wes McKinney | pandas, numpy, matplotlib |
| *Hands-On Machine Learning* (3rd ed.) | AurÃ©lien GÃ©ron | sklearn, xgboost, mÃ©tricas |
| *Interpretable Machine Learning* | Christoph Molnar | SHAP, PDP, LIME (gratis en lÃ­nea) |
| *The Kaggle Book* | Banachewicz & Massaron | Feature engineering, competencias |

### Canales de YouTube Recomendados
| Canal | Enfoque |
|-------|---------|
| [StatQuest with Josh Starmer](https://www.youtube.com/@statquest) | EstadÃ­stica y ML visual, sin matemÃ¡ticas densas |
| [Corey Schafer](https://www.youtube.com/@coreyms) | Python intermedio, pandas, matplotlib |
| [Krish Naik](https://www.youtube.com/@krishnaik06) | ML aplicado, SHAP, deployment |
| [Guy in a Cube](https://www.youtube.com/@GuyInACube) | Power BI profesional |

### DocumentaciÃ³n Oficial (marcar como favoritos)
- [pandas](https://pandas.pydata.org/docs/) â€” especialmente User Guide > Time Series
- [scikit-learn](https://scikit-learn.org/stable/user_guide.html) â€” User Guide completo
- [LightGBM](https://lightgbm.readthedocs.io/)
- [SHAP](https://shap.readthedocs.io/)
- [FastAPI](https://fastapi.tiangolo.com/)

---

*Ãšltima actualizaciÃ³n: 2026-02-18 | VersiÃ³n: 1.0*
*Para actualizar este plan, editarlo directamente y hacer commit con mensaje `docs: update study plan`*
